{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!sudo echo -ne '\\n' | sudo add-apt-repository ppa:alessandro-strada/ppa >/dev/null 2>&1 # note: >/dev/null 2>&1 is used to supress printing\n",
        "!sudo apt update >/dev/null 2>&1\n",
        "!sudo apt install google-drive-ocamlfuse >/dev/null 2>&1\n",
        "!google-drive-ocamlfuse\n",
        "!sudo apt-get install w3m >/dev/null 2>&1 # to act as web browser \n",
        "!xdg-settings set default-web-browser w3m.desktop >/dev/null 2>&1 # to set default browser \n",
        "%cd /content\n",
        "!mkdir gdrive\n",
        "%cd gdrive\n",
        "!mkdir \"My Drive\"\n",
        "!google-drive-ocamlfuse \"/content/gdrive/My Drive\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KceLS3OvmUNK",
        "outputId": "aa5691ff-16e4-45de-ef47-c3b1955eb68a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: www-browser: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: links2: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: elinks: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: links: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: lynx: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: w3m: not found\n",
            "xdg-open: no method available for opening 'https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=qu9XFcz8T43uzUHKdzImYH8XDELfjnMpIWuQ6EeBL6I'\n",
            "/bin/sh: 1: firefox: not found\n",
            "/bin/sh: 1: google-chrome: not found\n",
            "/bin/sh: 1: chromium-browser: not found\n",
            "/bin/sh: 1: open: not found\n",
            "Cannot retrieve auth tokens.\n",
            "Failure(\"Error opening URL:https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=qu9XFcz8T43uzUHKdzImYH8XDELfjnMpIWuQ6EeBL6I\")\n",
            "/content\n",
            "/content/gdrive\n",
            "Access token retrieved correctly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting root path for the project"
      ],
      "metadata": {
        "id": "xTbBrW9JBHd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = \"/content/gdrive/My Drive/Project_Dataset_MSVD\"\n",
        "!pip install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eY3xlqKJBHFf",
        "outputId": "8e022023-3b0b-4ac7-c7a3-b357492ec4d3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6084 sha256=bd74203a2f34a7ceddfecbefe5b8e30e6625c53314e0e52130d38f12075fc83d\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/33/46/5ab7eca55b9490dddbf3441c68a29535996270ef1ce8b9b6d7\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "importing libraries"
      ],
      "metadata": {
        "id": "ccUIhTA7lRI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess, ffmpeg, multiprocessing, os, shutil,cv2, json\n",
        "from multiprocessing import Pool\n",
        "import numpy as np\n",
        "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
        "from PIL import Image\n",
        "import torch as th\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from keras.engine.training import Model\n",
        "from keras.layers.regularization.spatial_dropout3d import Dropout\n",
        "from keras.layers.core.dense import Dense\n",
        "from keras.layers.reshaping.flatten import Flatten\n",
        "from keras.layers.pooling.average_pooling2d import AveragePooling2D\n",
        "from keras.layers import Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import SGD\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm"
      ],
      "metadata": {
        "id": "Rmc9esBCDkl4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to compress videos"
      ],
      "metadata": {
        "id": "O43XmCfalUdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compress_video(input_path, output_path):\n",
        "  try:\n",
        "    command = [\n",
        "        'ffmpeg',\n",
        "        '-y','-i', input_path,\n",
        "        '-filter:v',\n",
        "        'scale=\\'if(gt(a,1),trunc(oh*a/2)*2,224)\\':\\'if(gt(a,1),224,trunc(ow*a/2)*2)\\'',\n",
        "        '-map','0:v',\n",
        "        '-r', '5',\n",
        "        output_path,\n",
        "    ]\n",
        "    ffmpeg = subprocess.Popen(command, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    out, err = ffmpeg.communicate()\n",
        "    return ffmpeg.poll()\n",
        "  except Exception as e:\n",
        "    raise e"
      ],
      "metadata": {
        "id": "mJtR1x1MCTY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining directories for training and test sets for videos"
      ],
      "metadata": {
        "id": "6C0N_aSVlefU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_video_path = root_path + \"/train_videos/train_videos\"\n",
        "test_video_path = root_path + \"/test_videos/test_videos\"\n",
        "cmpd_train_video_path = root_path + \"/ten_class_train_set\"\n",
        "cmpd_test_video_path = root_path + \"/ten_class_test_set\"\n",
        "input_path_list = []"
      ],
      "metadata": {
        "id": "TNWH-xudFd6D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "getting annotation data on train set"
      ],
      "metadata": {
        "id": "qRyVfCDWwtiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_anno = root_path + \"/train_annotations/train_annotations.json\"\n",
        "json_file = open(train_anno)\n",
        "annotations = json.load(json_file)\n",
        "json_file.close()"
      ],
      "metadata": {
        "id": "9bLsYF7gj9qT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating annotation dictionary to be used later"
      ],
      "metadata": {
        "id": "9OIr0LnH07-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anno_dict = {}\n",
        "for item in annotations[\"videos\"]:\n",
        "  anno_dict[item['video_id'] + '.mp4'] = item[\"category\"]"
      ],
      "metadata": {
        "id": "5HBHpwHaCLqo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "filtering out 50 videos of first 5 categories"
      ],
      "metadata": {
        "id": "HrWoQd2KxC-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = [\n",
        "    [item for item in annotations[\"videos\"] if item[\"category\"] == 0][0:10],\n",
        "    [item for item in annotations[\"videos\"] if item[\"category\"] == 8][0:10],\n",
        "    [item for item in annotations[\"videos\"] if item[\"category\"] == 9][0:10],\n",
        "    [item for item in annotations[\"videos\"] if item[\"category\"] == 11][0:10],\n",
        "    [item for item in annotations[\"videos\"] if item[\"category\"] == 16][0:10],\n",
        "    ]"
      ],
      "metadata": {
        "id": "lLgqWuCCkrfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = sum(train_set, [])\n",
        "len(train_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxeITq1Pk3Yc",
        "outputId": "8bb07fe5-383c-4851-90df-57ca1111c64f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for row in train_set:\n",
        "  name = row[\"video_id\"]\n",
        "  input_file_name = train_video_path + \"/\" + name + \".mp4\"\n",
        "  output_file_name = cmpd_train_video_path + \"/\" + name + \".mp4\"\n",
        "  print(output_file_name)\n",
        "  compress_video(input_file_name, output_file_name)"
      ],
      "metadata": {
        "id": "JzKii1nXfKQd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd94e5ed-82ae-47de-af69-7e51972a15fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video27.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video43.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video47.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video48.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video56.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video66.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video97.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video106.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video119.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video127.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video3.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video71.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video77.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video87.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video109.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video218.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video286.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video288.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video332.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video373.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video0.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video2.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video25.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video42.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video64.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video86.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video115.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video120.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video125.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video140.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video107.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video112.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video134.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video168.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video181.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video244.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video317.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video339.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video489.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video532.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video1.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video22.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video35.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video68.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video72.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video88.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video103.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video118.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video123.mp4\n",
            "/content/gdrive/My Drive/Project_Dataset_MSVD/ten_class_train_set/video144.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering out test set"
      ],
      "metadata": {
        "id": "ALgQ6yyJ0aZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = [\n",
        "    [item for item in annotations[\"videos\"] if item[\"category\"] == 0][10:21],\n",
        "    [item for item in annotations[\"videos\"] if item[\"category\"] == 8][10:21],\n",
        "    [item for item in annotations[\"videos\"] if item[\"category\"] == 9][10:21],\n",
        "    [item for item in annotations[\"videos\"] if item[\"category\"] == 11][10:21],\n",
        "    [item for item in annotations[\"videos\"] if item[\"category\"] == 16][10:21],\n",
        "    ]"
      ],
      "metadata": {
        "id": "cFdse-0A0W82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = sum(test_set, [])\n",
        "len(test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKLKHvjV020t",
        "outputId": "ec0aac68-74d2-4a4d-a9b3-4c9467686767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for row in test_set:\n",
        "  name = row[\"video_id\"]\n",
        "  input_file_name = train_video_path + \"/\" + name + \".mp4\"\n",
        "  output_file_name = cmpd_test_video_path + \"/\" + name + \".mp4\"\n",
        "  compress_video(input_file_name, output_file_name)"
      ],
      "metadata": {
        "id": "3YTT0KdgmMWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "code snippet to convert video to tensor :-\n",
        "\n",
        "transform_image function is used to apply transformations and normalizations to the image\n"
      ],
      "metadata": {
        "id": "vgtewQQt0K5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_image(resolution):\n",
        "  result = Compose([\n",
        "      Resize(resolution, interpolation=Image.BICUBIC),\n",
        "      CenterCrop(resolution),\n",
        "      lambda image: image.convert(\"RGB\"),\n",
        "      ToTensor(),\n",
        "      Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
        "  ])\n",
        "  return result"
      ],
      "metadata": {
        "id": "xwYZ7zXTDUts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "actual conversion of all video files in the train directory"
      ],
      "metadata": {
        "id": "_H6u_qk6m24l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_videos = os.listdir(cmpd_train_video_path) \n",
        "videos = []\n",
        "labels = []\n",
        "for file_t in list_of_videos:\n",
        "  t_video = cmpd_train_video_path + \"/\" + file_t\n",
        "  cap = cv2.VideoCapture(t_video)\n",
        "  frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "  interval = 1\n",
        "  total_duration = (frameCount + fps - 1) // fps\n",
        "  indexes = [index for index in np.arange(0, fps, interval)]\n",
        "\n",
        "  return_code = True\n",
        "  images, included = [],[]\n",
        "  img_preprocess = transform_image(224)\n",
        "\n",
        "  for seconds in np.arange(0,total_duration + 1):\n",
        "    if not return_code: \n",
        "      break\n",
        "    seconds_base = int(seconds*fps)\n",
        "    for index in indexes:\n",
        "      cap.set(cv2.CAP_PROP_POS_FRAMES, seconds_base + index)\n",
        "      return_code, frame = cap.read()\n",
        "      if not return_code: \n",
        "        break\n",
        "      frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "      frame = img_preprocess(Image.fromarray(frame_rgb).convert(\"RGB\"))\n",
        "      videos.append(frame)\n",
        "      labels.append(anno_dict[file_t])\n",
        "  cap.release()"
      ],
      "metadata": {
        "id": "Jo-x23As0N13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ce9eef2-6a4a-48e2-972f-ac9e9fcfe1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shifting the axis of images from (3,224,224) to (224,224,3) shape"
      ],
      "metadata": {
        "id": "Dp6AoQWrqSuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(videos)):\n",
        "  frames = videos[i]\n",
        "  temp_frames = frames.permute(2,1,0)\n",
        "  videos[i] = temp_frames\n"
      ],
      "metadata": {
        "id": "UNmod2UhSfqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "videos_np = [t.numpy() for t in videos]\n",
        "videos_np = np.array(videos_np)"
      ],
      "metadata": {
        "id": "CXNFYM9dMknN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "videos_np.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c0O5RO6MpeX",
        "outputId": "d46c410c-92e2-4e3a-a5d6-fbae3727eaea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3495, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_np = np.array(labels)"
      ],
      "metadata": {
        "id": "mGPXr2T7DxQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_bin = LabelBinarizer()\n",
        "labels_np = label_bin.fit_transform(labels)"
      ],
      "metadata": {
        "id": "_BnklvtlFiR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_aug = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.3,\n",
        "    shear_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "val_aug = ImageDataGenerator()\n",
        "mean = np.array([123.68,116.779,103.939], dtype=\"float32\")\n",
        "train_aug.mean = mean\n",
        "val_aug.mean = mean"
      ],
      "metadata": {
        "id": "E7bp_su-GcKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "actual conversion of all video files in the test directory"
      ],
      "metadata": {
        "id": "fO_Xv6zcOY9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_videos = os.listdir(cmpd_test_video_path) \n",
        "videos = []\n",
        "for file_t in list_of_videos:\n",
        "  t_video = cmpd_test_video_path + \"/\" + file_t\n",
        "  cap = cv2.VideoCapture(t_video)\n",
        "  frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "  interval = 1\n",
        "  total_duration = (frameCount + fps - 1) // fps\n",
        "  indexes = [index for index in np.arange(0, fps, interval)]\n",
        "\n",
        "  return_code = True\n",
        "  images, included = [],[]\n",
        "  img_preprocess = transform_image(224)\n",
        "\n",
        "  for seconds in np.arange(0,total_duration + 1):\n",
        "    if not return_code: \n",
        "      break\n",
        "    seconds_base = int(seconds*fps)\n",
        "    for index in indexes:\n",
        "      cap.set(cv2.CAP_PROP_POS_FRAMES, seconds_base + index)\n",
        "      return_code, frame = cap.read()\n",
        "      if not return_code: \n",
        "        break\n",
        "      frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "      frame = img_preprocess(Image.fromarray(frame_rgb).convert(\"RGB\"))\n",
        "      images.append(frame)\n",
        "  videos.append((images, file_t)) \n",
        "  cap.release()"
      ],
      "metadata": {
        "id": "2EzCEe6-Oa30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c86c6e1b-7558-4151-e2f3-74091b9ebfb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "formatting frames data"
      ],
      "metadata": {
        "id": "AKA7OWqXuDxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(videos)):\n",
        "  frames = videos[i][0]\n",
        "  frames = frames[0:50]\n",
        "  for j in range(len(frames)):\n",
        "    frame = frames[j]\n",
        "    frame = frame.permute(2,1,0)\n",
        "    frames[j] = frame\n",
        "  videos[i] = (frames, videos[i][1])"
      ],
      "metadata": {
        "id": "EN2PfRerP2EF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Res Net model"
      ],
      "metadata": {
        "id": "Iiu9S3tmHg9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orig_res_net_model = tf.keras.applications.ResNet50(\n",
        "    weights=\"imagenet\", \n",
        "    include_top=False, \n",
        "    input_tensor=Input(shape=(224,224,3)))\n",
        "aug_model = orig_res_net_model.output\n",
        "aug_model = AveragePooling2D(pool_size=(7,7))(aug_model)\n",
        "aug_model = Flatten(name=\"flatten\")(aug_model)\n",
        "aug_model = Dense(1024, activation=\"relu\")(aug_model)\n",
        "aug_model = Dropout(0.5)(aug_model)\n",
        "aug_model = Dense(len(label_bin.classes_), activation=\"softmax\")(aug_model)\n",
        "\n",
        "final_model = Model(inputs=orig_res_net_model.input, outputs=aug_model)\n",
        "\n",
        "# marking resnet layer as untrainable\n",
        "for layer in orig_res_net_model.layers:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "7ucD-kK4HjZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(trainX, validX, trainY, validY) = train_test_split(videos_np, labels_np,\n",
        "\ttest_size=0.25, stratify=labels, random_state=42)"
      ],
      "metadata": {
        "id": "-2nQY6H2NleZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "using stochastic gradient descent optimizer with loss as categorical crossentropy"
      ],
      "metadata": {
        "id": "UueeY81Gsugo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "\n",
        "optObj = SGD(lr=1e-3, momentum=0.8, decay=(1e-4 / epochs))\n",
        "final_model.compile(loss=\"categorical_crossentropy\", optimizer=optObj,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "history = final_model.fit(\n",
        "\tx=train_aug.flow(trainX, trainY, batch_size=32),\n",
        "  validation_data=val_aug.flow(validX, validY),\n",
        "\tvalidation_steps=len(validX) // 32,\n",
        "\tsteps_per_epoch=len(trainX) // 32,\n",
        "\tepochs=epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_jsj_EjKm1d",
        "outputId": "7089972d-54a6-40b7-88f9-da14d9b915c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "81/81 [==============================] - 44s 406ms/step - loss: 1.6636 - accuracy: 0.2835 - val_loss: 1.4001 - val_accuracy: 0.4618\n",
            "Epoch 2/50\n",
            "81/81 [==============================] - 34s 423ms/step - loss: 1.4604 - accuracy: 0.3801 - val_loss: 1.3316 - val_accuracy: 0.4815\n",
            "Epoch 3/50\n",
            "81/81 [==============================] - 34s 424ms/step - loss: 1.3865 - accuracy: 0.4214 - val_loss: 1.3092 - val_accuracy: 0.4826\n",
            "Epoch 4/50\n",
            "81/81 [==============================] - 31s 379ms/step - loss: 1.3337 - accuracy: 0.4654 - val_loss: 1.2467 - val_accuracy: 0.5231\n",
            "Epoch 5/50\n",
            "81/81 [==============================] - 31s 387ms/step - loss: 1.2878 - accuracy: 0.4936 - val_loss: 1.1931 - val_accuracy: 0.5961\n",
            "Epoch 6/50\n",
            "81/81 [==============================] - 31s 379ms/step - loss: 1.2660 - accuracy: 0.5033 - val_loss: 1.1688 - val_accuracy: 0.5613\n",
            "Epoch 7/50\n",
            "81/81 [==============================] - 31s 383ms/step - loss: 1.2201 - accuracy: 0.5299 - val_loss: 1.1508 - val_accuracy: 0.6007\n",
            "Epoch 8/50\n",
            "81/81 [==============================] - 33s 403ms/step - loss: 1.2172 - accuracy: 0.5435 - val_loss: 1.1198 - val_accuracy: 0.6076\n",
            "Epoch 9/50\n",
            "81/81 [==============================] - 31s 378ms/step - loss: 1.1689 - accuracy: 0.5662 - val_loss: 1.1021 - val_accuracy: 0.5972\n",
            "Epoch 10/50\n",
            "81/81 [==============================] - 31s 383ms/step - loss: 1.1611 - accuracy: 0.5562 - val_loss: 1.1112 - val_accuracy: 0.5833\n",
            "Epoch 11/50\n",
            "81/81 [==============================] - 31s 378ms/step - loss: 1.1298 - accuracy: 0.5732 - val_loss: 1.0700 - val_accuracy: 0.6204\n",
            "Epoch 12/50\n",
            "81/81 [==============================] - 31s 379ms/step - loss: 1.1161 - accuracy: 0.5883 - val_loss: 1.0512 - val_accuracy: 0.6157\n",
            "Epoch 13/50\n",
            "81/81 [==============================] - 31s 378ms/step - loss: 1.0973 - accuracy: 0.5894 - val_loss: 1.0251 - val_accuracy: 0.6285\n",
            "Epoch 14/50\n",
            "81/81 [==============================] - 31s 379ms/step - loss: 1.1016 - accuracy: 0.5867 - val_loss: 1.0218 - val_accuracy: 0.6250\n",
            "Epoch 15/50\n",
            "81/81 [==============================] - 31s 380ms/step - loss: 1.0681 - accuracy: 0.6056 - val_loss: 1.0232 - val_accuracy: 0.6250\n",
            "Epoch 16/50\n",
            "81/81 [==============================] - 31s 380ms/step - loss: 1.0809 - accuracy: 0.5929 - val_loss: 0.9798 - val_accuracy: 0.6412\n",
            "Epoch 17/50\n",
            "81/81 [==============================] - 34s 418ms/step - loss: 1.0482 - accuracy: 0.6053 - val_loss: 0.9785 - val_accuracy: 0.6586\n",
            "Epoch 18/50\n",
            "81/81 [==============================] - 31s 381ms/step - loss: 1.0373 - accuracy: 0.6118 - val_loss: 0.9577 - val_accuracy: 0.6667\n",
            "Epoch 19/50\n",
            "81/81 [==============================] - 31s 378ms/step - loss: 1.0242 - accuracy: 0.6238 - val_loss: 0.9599 - val_accuracy: 0.6470\n",
            "Epoch 20/50\n",
            "81/81 [==============================] - 31s 379ms/step - loss: 1.0057 - accuracy: 0.6346 - val_loss: 0.9394 - val_accuracy: 0.6528\n",
            "Epoch 21/50\n",
            "81/81 [==============================] - 31s 380ms/step - loss: 1.0001 - accuracy: 0.6385 - val_loss: 0.9303 - val_accuracy: 0.6759\n",
            "Epoch 22/50\n",
            "81/81 [==============================] - 31s 376ms/step - loss: 0.9926 - accuracy: 0.6300 - val_loss: 0.9082 - val_accuracy: 0.6632\n",
            "Epoch 23/50\n",
            "81/81 [==============================] - 31s 380ms/step - loss: 0.9804 - accuracy: 0.6365 - val_loss: 0.8950 - val_accuracy: 0.7025\n",
            "Epoch 24/50\n",
            "81/81 [==============================] - 31s 376ms/step - loss: 0.9736 - accuracy: 0.6404 - val_loss: 0.8960 - val_accuracy: 0.6620\n",
            "Epoch 25/50\n",
            "81/81 [==============================] - 33s 403ms/step - loss: 0.9562 - accuracy: 0.6551 - val_loss: 0.8870 - val_accuracy: 0.6944\n",
            "Epoch 26/50\n",
            "81/81 [==============================] - 31s 376ms/step - loss: 0.9546 - accuracy: 0.6504 - val_loss: 0.8895 - val_accuracy: 0.6701\n",
            "Epoch 27/50\n",
            "81/81 [==============================] - 31s 379ms/step - loss: 0.9394 - accuracy: 0.6504 - val_loss: 0.8555 - val_accuracy: 0.6979\n",
            "Epoch 28/50\n",
            "81/81 [==============================] - 31s 376ms/step - loss: 0.9451 - accuracy: 0.6531 - val_loss: 0.8445 - val_accuracy: 0.7014\n",
            "Epoch 29/50\n",
            "81/81 [==============================] - 31s 379ms/step - loss: 0.9084 - accuracy: 0.6725 - val_loss: 0.8448 - val_accuracy: 0.7095\n",
            "Epoch 30/50\n",
            "81/81 [==============================] - 31s 380ms/step - loss: 0.9355 - accuracy: 0.6566 - val_loss: 0.8542 - val_accuracy: 0.7049\n",
            "Epoch 31/50\n",
            "81/81 [==============================] - 31s 377ms/step - loss: 0.9144 - accuracy: 0.6601 - val_loss: 0.8288 - val_accuracy: 0.7164\n",
            "Epoch 32/50\n",
            "81/81 [==============================] - 31s 381ms/step - loss: 0.9141 - accuracy: 0.6705 - val_loss: 0.8206 - val_accuracy: 0.7153\n",
            "Epoch 33/50\n",
            "81/81 [==============================] - 33s 401ms/step - loss: 0.8987 - accuracy: 0.6663 - val_loss: 0.8126 - val_accuracy: 0.7164\n",
            "Epoch 34/50\n",
            "81/81 [==============================] - 31s 378ms/step - loss: 0.8924 - accuracy: 0.6748 - val_loss: 0.8011 - val_accuracy: 0.7211\n",
            "Epoch 35/50\n",
            "81/81 [==============================] - 31s 378ms/step - loss: 0.8785 - accuracy: 0.6790 - val_loss: 0.8091 - val_accuracy: 0.7326\n",
            "Epoch 36/50\n",
            "81/81 [==============================] - 30s 374ms/step - loss: 0.8756 - accuracy: 0.6833 - val_loss: 0.8119 - val_accuracy: 0.7234\n",
            "Epoch 37/50\n",
            "81/81 [==============================] - 31s 378ms/step - loss: 0.8728 - accuracy: 0.6821 - val_loss: 0.8138 - val_accuracy: 0.6991\n",
            "Epoch 38/50\n",
            "81/81 [==============================] - 30s 376ms/step - loss: 0.8673 - accuracy: 0.6798 - val_loss: 0.7976 - val_accuracy: 0.7002\n",
            "Epoch 39/50\n",
            "81/81 [==============================] - 31s 377ms/step - loss: 0.8546 - accuracy: 0.6960 - val_loss: 0.8013 - val_accuracy: 0.7130\n",
            "Epoch 40/50\n",
            "81/81 [==============================] - 31s 380ms/step - loss: 0.8553 - accuracy: 0.6829 - val_loss: 0.7785 - val_accuracy: 0.7234\n",
            "Epoch 41/50\n",
            "81/81 [==============================] - 31s 379ms/step - loss: 0.8438 - accuracy: 0.7061 - val_loss: 0.7732 - val_accuracy: 0.7338\n",
            "Epoch 42/50\n",
            "81/81 [==============================] - 33s 400ms/step - loss: 0.8513 - accuracy: 0.6860 - val_loss: 0.7379 - val_accuracy: 0.7373\n",
            "Epoch 43/50\n",
            "81/81 [==============================] - 31s 379ms/step - loss: 0.8263 - accuracy: 0.7065 - val_loss: 0.7334 - val_accuracy: 0.7569\n",
            "Epoch 44/50\n",
            "81/81 [==============================] - 31s 378ms/step - loss: 0.8324 - accuracy: 0.6983 - val_loss: 0.7398 - val_accuracy: 0.7500\n",
            "Epoch 45/50\n",
            "81/81 [==============================] - 31s 377ms/step - loss: 0.8219 - accuracy: 0.7034 - val_loss: 0.7359 - val_accuracy: 0.7292\n",
            "Epoch 46/50\n",
            "81/81 [==============================] - 30s 375ms/step - loss: 0.8381 - accuracy: 0.6925 - val_loss: 0.7402 - val_accuracy: 0.7546\n",
            "Epoch 47/50\n",
            "81/81 [==============================] - 31s 378ms/step - loss: 0.8002 - accuracy: 0.7084 - val_loss: 0.7327 - val_accuracy: 0.7500\n",
            "Epoch 48/50\n",
            "81/81 [==============================] - 31s 378ms/step - loss: 0.8120 - accuracy: 0.7053 - val_loss: 0.7243 - val_accuracy: 0.7535\n",
            "Epoch 49/50\n",
            "81/81 [==============================] - 31s 378ms/step - loss: 0.8075 - accuracy: 0.7192 - val_loss: 0.7211 - val_accuracy: 0.7523\n",
            "Epoch 50/50\n",
            "81/81 [==============================] - 32s 400ms/step - loss: 0.7916 - accuracy: 0.7099 - val_loss: 0.7180 - val_accuracy: 0.7546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the weights of model"
      ],
      "metadata": {
        "id": "aqfBZE3StYIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.save(root_path + \"/res_net_model_1024\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_l1jJinX7qF",
        "outputId": "e4e5b1be-892e-4949-9aea-badf1e7a8351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading weights of the model"
      ],
      "metadata": {
        "id": "4AqCgv0XFixl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = tf.keras.models.load_model(root_path + \"/res_net_model_1024\")"
      ],
      "metadata": {
        "id": "-ShiqpCsFikv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "extracting reduced representation vectors"
      ],
      "metadata": {
        "id": "HrB6EZ1ttkOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "get_all_layer_outputs = K.function([final_model.layers[0].input],\n",
        "                                  [layer.output for layer in final_model.layers[1:]])\n",
        "\n",
        "video_simi = []\n",
        "for frames in videos:\n",
        "  vectors = []\n",
        "  for frame in frames[0]:\n",
        "    frame = np.array([frame.numpy()])\n",
        "    print(frame.shape)\n",
        "    layer_output = get_all_layer_outputs([frame])\n",
        "    vectors.append(layer_output[-3].flatten())\n",
        "  video_simi.append((vectors,frames[1]))"
      ],
      "metadata": {
        "id": "kOVHHalqZJKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(video_simi[0][0][2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV4OG479bBjW",
        "outputId": "68f80f28-fbaf-4802-e656-fa777ca2cb5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "storing vectors as inverted indexes for videos"
      ],
      "metadata": {
        "id": "YhNhg7loyszM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "with open(root_path + '/inverted_index_1024.csv','w', encoding='utf-8') as out:\n",
        "    csv_out=csv.writer(out, delimiter=\";\")\n",
        "    for i in range(len(video_simi)):\n",
        "      frames = video_simi[i][0]\n",
        "      row_f = []\n",
        "      for row in frames:\n",
        "          v = \",\".join(map(str, row.tolist()))\n",
        "          row_f.append(v)\n",
        "      row_f.append(video_simi[i][1])\n",
        "      csv_out.writerow(row_f)"
      ],
      "metadata": {
        "id": "TBUzE9EaULFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "reading inverted indexes from file"
      ],
      "metadata": {
        "id": "XfwNyvlUyy5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "csv_file_path = root_path + \"/inverted_index_1024.csv\"\n",
        "inverted_index_read = []\n",
        "with open(csv_file_path, newline='') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=\";\")\n",
        "    for row in reader:\n",
        "      line = []\n",
        "      for i in range(len(row) - 1):\n",
        "        cell = row[i]\n",
        "        vector = cell.split(\",\")\n",
        "        vector = [float(i) for i in vector]\n",
        "        line.append(vector)\n",
        "      inverted_index_read.append((line,row[-1]))"
      ],
      "metadata": {
        "id": "SwykNXfEYL-y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(inverted_index_read)"
      ],
      "metadata": {
        "id": "E3UKM-naoPHQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cad4ba02-e741-435f-e4f8-062da5eb008a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 0\n",
        "for item in inverted_index_read:\n",
        "  print(counter, item[1])\n",
        "  counter += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5g0dxZMKrx2",
        "outputId": "6879e868-a3f5-4d04-b4a5-ce2f8b147ddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 video307.mp4\n",
            "1 video544.mp4\n",
            "2 video171.mp4\n",
            "3 video225.mp4\n",
            "4 video207.mp4\n",
            "5 video216.mp4\n",
            "6 video222.mp4\n",
            "7 video574.mp4\n",
            "8 video631.mp4\n",
            "9 video255.mp4\n",
            "10 video194.mp4\n",
            "11 video543.mp4\n",
            "12 video315.mp4\n",
            "13 video575.mp4\n",
            "14 video739.mp4\n",
            "15 video823.mp4\n",
            "16 video214.mp4\n",
            "17 video598.mp4\n",
            "18 video173.mp4\n",
            "19 video751.mp4\n",
            "20 video730.mp4\n",
            "21 video678.mp4\n",
            "22 video645.mp4\n",
            "23 video189.mp4\n",
            "24 video185.mp4\n",
            "25 video153.mp4\n",
            "26 video660.mp4\n",
            "27 video243.mp4\n",
            "28 video259.mp4\n",
            "29 video402.mp4\n",
            "30 video619.mp4\n",
            "31 video652.mp4\n",
            "32 video237.mp4\n",
            "33 video250.mp4\n",
            "34 video230.mp4\n",
            "35 video251.mp4\n",
            "36 video668.mp4\n",
            "37 video496.mp4\n",
            "38 video474.mp4\n",
            "39 video329.mp4\n",
            "40 video202.mp4\n",
            "41 video285.mp4\n",
            "42 video149.mp4\n",
            "43 video154.mp4\n",
            "44 video145.mp4\n",
            "45 video274.mp4\n",
            "46 video539.mp4\n",
            "47 video326.mp4\n",
            "48 video227.mp4\n",
            "49 video386.mp4\n",
            "50 video500.mp4\n",
            "51 video325.mp4\n",
            "52 video296.mp4\n",
            "53 video152.mp4\n",
            "54 video318.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "different query images"
      ],
      "metadata": {
        "id": "FOQx5sXty6rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = inverted_index_read[23] # for category 9\n",
        "# query = inverted_index_read[13] # for category 11\n",
        "# query = inverted_index_read[25] # for category 16\n",
        "# query = inverted_index_read[17] # for category 8\n",
        "# query = inverted_index_read[24] # for category 0\n",
        "# query"
      ],
      "metadata": {
        "id": "GyHM2C-EajZE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_queries = [\n",
        "    inverted_index_read[23],\n",
        "    inverted_index_read[13],\n",
        "    inverted_index_read[25],\n",
        "    inverted_index_read[17],\n",
        "    inverted_index_read[24]\n",
        "]"
      ],
      "metadata": {
        "id": "N5g_Emhfp91R"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QCulgYHaiOBm",
        "outputId": "d48f1a6b-aa0c-47b8-e918-a5c14c692d50"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'video189.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cosine similarity function"
      ],
      "metadata": {
        "id": "ldoIwSPIzFF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_sim(a,b):\n",
        "  cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
        "  return cos_sim"
      ],
      "metadata": {
        "id": "3p1qd7N7asPX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "function to fetch top k results after applying cosine similarity on dataset"
      ],
      "metadata": {
        "id": "hG6fGG37zHsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_n(query, dataset, n_v = 10):\n",
        "  results = []\n",
        "  for item in dataset:\n",
        "    vec_l, name = item\n",
        "    key = name.split(\".\")[0]\n",
        "    simi = 0\n",
        "    for i in range(len(query[0]) - 1):\n",
        "      simi += cosine_sim(vec_l[i],query[0][i])\n",
        "    simi = simi / (len(query[0]) - 1)\n",
        "    results.append((simi, name, anno_dict[name]))\n",
        "  results = sorted(results,key=lambda x: x[0], reverse=True)\n",
        "  return results"
      ],
      "metadata": {
        "id": "gkoTnd6SazsD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = get_top_n(query, inverted_index_read)"
      ],
      "metadata": {
        "id": "sHUw3owmgPrP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code used to export results for combined model"
      ],
      "metadata": {
        "id": "HFISKEg-rvAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_file = {}\n",
        "for query in all_queries:\n",
        "  query_v, file_name = query\n",
        "  result = get_top_n(query, inverted_index_read, n_v=55)\n",
        "  results_file[file_name] = result\n",
        "\n",
        "with open(root_path + \"/query_results_model_video_250.json\", 'w') as comb:\n",
        "     comb.write(json.dumps(results_file))\n"
      ],
      "metadata": {
        "id": "kfcCsLvFo-At"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results[0:11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CovidZNqn1lA",
        "outputId": "89e0ce6d-631a-4725-d74f-24ee46a09006"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1.0, 'video189.mp4', 9),\n",
              " (0.6703097338556789, 'video216.mp4', 0),\n",
              " (0.6626272010706061, 'video227.mp4', 0),\n",
              " (0.6347418613162646, 'video307.mp4', 16),\n",
              " (0.6286260364620005, 'video207.mp4', 0),\n",
              " (0.6188768395634379, 'video315.mp4', 16),\n",
              " (0.6157986347815437, 'video237.mp4', 0),\n",
              " (0.610284672096311, 'video251.mp4', 9),\n",
              " (0.6077471999035507, 'video243.mp4', 9),\n",
              " (0.5957739595941812, 'video202.mp4', 16),\n",
              " (0.5899047874328825, 'video259.mp4', 9)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results1[0:11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AacjGJYpIFN",
        "outputId": "6f5448ec-e0e3-4395-d437-32c1e521571e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1.0, 'video575.mp4', 11),\n",
              " (0.7851996240041729, 'video645.mp4', 11),\n",
              " (0.7582690577413368, 'video730.mp4', 11),\n",
              " (0.7167215237736637, 'video214.mp4', 16),\n",
              " (0.7056470414466052, 'video619.mp4', 11),\n",
              " (0.6959792146340015, 'video225.mp4', 16),\n",
              " (0.6697355814744039, 'video539.mp4', 11),\n",
              " (0.6571184797728028, 'video318.mp4', 16),\n",
              " (0.6535704670103986, 'video227.mp4', 0),\n",
              " (0.6392935688164175, 'video149.mp4', 9),\n",
              " (0.6320930020639072, 'video259.mp4', 9)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results2[0:11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIWxCikzpaMA",
        "outputId": "410bd1bd-3b89-49a6-fdb3-19bc3a9842ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1.0, 'video153.mp4', 16),\n",
              " (0.6530558987045518, 'video207.mp4', 0),\n",
              " (0.6312752594004393, 'video227.mp4', 0),\n",
              " (0.6307707617222873, 'video173.mp4', 16),\n",
              " (0.6254667976357589, 'video315.mp4', 16),\n",
              " (0.6245295374842468, 'video259.mp4', 9),\n",
              " (0.6183636806777882, 'video222.mp4', 16),\n",
              " (0.6089380267570451, 'video251.mp4', 9),\n",
              " (0.6043947408815741, 'video237.mp4', 0),\n",
              " (0.5992221539736123, 'video202.mp4', 16),\n",
              " (0.5972405030375064, 'video250.mp4', 9)]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results3[0:11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsaQXHiXphZH",
        "outputId": "eace7131-cc45-4c59-8119-3bb4aa2d785e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1.0, 'video598.mp4', 8),\n",
              " (0.7815737509595672, 'video668.mp4', 8),\n",
              " (0.7670388339530188, 'video285.mp4', 16),\n",
              " (0.7423009707854442, 'video326.mp4', 0),\n",
              " (0.72441439714572, 'video539.mp4', 11),\n",
              " (0.7197196246607542, 'video296.mp4', 9),\n",
              " (0.7151423245848995, 'video543.mp4', 11),\n",
              " (0.7022370594513427, 'video318.mp4', 16),\n",
              " (0.6869392680911509, 'video474.mp4', 8),\n",
              " (0.6855807971152071, 'video386.mp4', 8),\n",
              " (0.6482417436959499, 'video152.mp4', 0)]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results4[0:11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FwyIdcapukF",
        "outputId": "596db90e-a80a-4388-e62d-4f5c8d8fca3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1.0, 'video185.mp4', 0),\n",
              " (0.7474358867325863, 'video227.mp4', 0),\n",
              " (0.7402216872031733, 'video194.mp4', 0),\n",
              " (0.7084008066348768, 'video619.mp4', 11),\n",
              " (0.6715736667098557, 'video202.mp4', 16),\n",
              " (0.6688757029342373, 'video645.mp4', 11),\n",
              " (0.6660583969079373, 'video207.mp4', 0),\n",
              " (0.654759946956365, 'video325.mp4', 0),\n",
              " (0.6267270058823632, 'video222.mp4', 16),\n",
              " (0.6153326478482293, 'video216.mp4', 0),\n",
              " (0.6108932775763013, 'video214.mp4', 16)]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "annotations"
      ],
      "metadata": {
        "id": "u81yLKmhcgn5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}